\documentclass[a4paper,11pt]{article} 
% Load some standard packages
\usepackage{amsmath,parskip,fullpage,natbib,bm} 

% Load tikz for the tree diagram
\usepackage{tikz}
\usetikzlibrary{trees,shapes}

% Define my own commands
\newcommand{\info}{{\cal I}}
\newcommand{\E}{\text{E}}

% Bibliography style
\bibliographystyle{agsm}

 \begin{document}
 	

\title{Mixed effects}
\author{Lucas}
\maketitle

\section{Mixed Models:}

In mixed effects models we consider both, random and fixed effects at the same time. Generally, the 
$N_i$ serial measurements (synonym?) $y_i$ of subject I are modelled as
\begin{equation}
	y_i=X_i\beta + Z_ib_i +\epsilon_i
\end{equation}
with $X_i$ being subject i’s $n_i*p$  design matrix containing fixed effects observations, beta the fixed effects regression coefficient vector of length $p$ to be estimated, $Z_i$’columns contain the subset of $X_i$’s we want to account for by random effects $b_i$, with epsilon being the residuals not explained by either fixed or random effects. More precisely, any component of $\beta$ can be allowed to vary randomly on the subject specific level by simply including the corresponding columns of $X$ in $Z$ (Bernal-Rusiel et al. , 2013)CHECK THIS. This will be further explored in the subsequent sections.\\
Here, the following assumptions made on the model are 
\begin{align*}
b_i &\sim \mathcal{N}(0,D)\\
\epsilon _i &\sim \mathcal{N}(0,\epsilon^2I_N)\\
\epsilon_1&,...,\epsilon_M,b_1,...,b_M  \text{independent},
\end{align*}

M is the number of subjects and bi represents the deviations of subject I from the populations coefficients for the subset $Z_i$, with D being the covariance matrix of $b_i$’s distribution. This allows subjects to deviate from the populations values, accounting for inter-subject variability (Zhang 2015).\\
The beauty of including random effects in our standard model is that it also permits us to model intra-subject measurement correlations. To show this, we will first distinguish the marginal (population-average) mean $E(y_i)$ from the conditional (subject-specific) mean $E(y_i|b_i)$:
\begin{align*}
		E(y_i)&=X_i\beta\\
		E(y_i|b_i)&=X_i\beta+Z_Ib_i
\end{align*}
Now we can compute the subject-specific covariance $Cov(y_i|b_i)$ and the population-average covariance $Cov(y_i)$:
\begin{align*}
	Cov(y_i|b_i)&=Cov(\epsilon_i)=\sigma^2I_{N_i}\\
	Cov(y_i)&=Cov(Z_ib_i)+Cov(\epsilon_i)=Z_iDZ_i^T+\sigma^2I_{N_i}
\end{align*}
While $\sigma^2$ is a diagonal matrix, $Z_iDZ_i^T$ is not. Hence, the addition of both, $Cov(y_i)$, is a matrix with off-diagonal elements, which enables us to model intra-subject measurement correlations.
Putting everything together, we get the common notation:
\begin{equation}\label{xy}
	y_i \sim\mathcal{N}(X_i\beta,H_i(\theta)),
\end{equation}
with $H_i=Z_iDZ_i^T + \sigma^2I_{N_i}$\\
Generally, the mixed effects model is useful when the data structure suggests there are good arguments for fixed and random effects, as opposed to the case where either one is preferred. This way we could account for population and individual effects. In the following section we will introduce two types of mixed effect models, to later explain the relevant estimation techniques. 

 \end{document} 